---
title: Self-Improving RAG System
emoji: ğŸ§ 
colorFrom: indigo
colorTo: purple
colorTo: purple
sdk: streamlit
sdk_version: 1.44.1
app_file: app.py
pinned: false
---

# ğŸ§  Self-Improving RAG System

A production-style Retrieval-Augmented Generation (RAG) system that evaluates its own answers, retries when confidence is low, and learns from human feedback.

This project demonstrates modern LLM architecture using:

- LangChain
- LangGraph
- Groq API (free inference)
- Streamlit UI
- Human feedback loop
- Self-evaluation pipeline

---

## ğŸš€ Features

âœ… PDF document ingestion  
âœ… Semantic retrieval (vector search)  
âœ… LLM answer generation  
âœ… Self-evaluation scoring  
âœ… Automatic retry logic  
âœ… Human feedback collection  
âœ… Fault-tolerant API handling  
âœ… Provider-agnostic LLM backend  
âœ… Deployable Streamlit app  

---

## ğŸ§  Why â€œSelf-Improvingâ€?

Unlike normal RAG systems that just answer once and stop, this system:

1. Evaluates its own answer using an LLM judge
2. Retries if confidence is low
3. Stores human feedback (ğŸ‘ / ğŸ‘)
4. Builds a dataset for continuous improvement

It doesnâ€™t just answer â€” it learns from its mistakes.

---

## ğŸ— Architecture

```
User Question
      â†“
Retriever (Vector DB)
      â†“
Generator LLM
      â†“
Evaluator LLM
      â†“
Retry if low score
      â†“
Store Feedback
```

This mirrors real-world AI production pipelines.

---

## ğŸ“‚ Project Structure

```
self_improving_rag/
â”‚
â”œâ”€â”€ app.py                 # Streamlit UI
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ loader.py          # PDF loader
â”‚   â”œâ”€â”€ retriever.py       # Vector retrieval
â”‚   â””â”€â”€ generator.py       # Answer generation
â”‚
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ evaluator.py       # Self-evaluation logic
â”‚
â”œâ”€â”€ graph/
â”‚   â””â”€â”€ rag_graph.py       # LangGraph workflow
â”‚
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ feedback_store.py  # Human feedback storage
â”‚   â””â”€â”€ feedback.json
â”‚
â””â”€â”€ requirements.txt
```

---

## âš™ Installation

### 1. Clone repo

```
git clone <your_repo_url>
cd self_improving_rag
```

### 2. Create virtual environment

```
python -m venv venv
venv\Scripts\activate
```

### 3. Install dependencies

```
pip install -r requirements.txt
```

---

## ğŸ”‘ API Setup (Groq)

Create a free Groq account:

ğŸ‘‰ https://console.groq.com

Create `.env` file:

```
GROQ_API_KEY=your_api_key_here
```

---

## â–¶ Run locally

```
python -m streamlit run app.py
```

Open browser â†’ upload PDF â†’ ask questions.

---

## â˜ Deploy on Hugging Face

1. Create Streamlit Space
2. Upload repo
3. Add secret:

```
GROQ_API_KEY
```

Your app is live ğŸ‰

---

## ğŸ“Š Example Use Case

Upload a resume â†’ ask:

> â€œWhat is his skill set?â€

System retrieves skills section, extracts structured skills, evaluates answer quality, and logs feedback.

---

## ğŸ¯ Skills Demonstrated

- Retrieval-Augmented Generation
- Prompt engineering
- Self-evaluation loops
- Human-in-the-loop AI
- Fault-tolerant API design
- LangGraph orchestration
- Vector search pipelines
- Production Streamlit deployment

---

## ğŸ”® Future Improvements

- Query rewriting
- Adaptive prompting
- Feedback analytics dashboard
- Structured JSON output
- Multi-document memory
- Active learning loop

---

## ğŸ§‘â€ğŸ’» Author

Built as an advanced LLM engineering project showcasing real-world RAG architecture.

---

## â­ If you like this project

Star the repo and share!

